# configuration for pretraining
# configurations needed in pretraining

batch_size: 1
epochs: 10
save_ckpt_freq: 1

# Model parameters
model: "pretrain_videomae_multimodal_base_patch16_224"
decoder_depth: 3
mask_type: "agnostic"         # choices=['tube']
mask_ratio: 0.9

modality: "rgbflow"

input_size: 224           # videos input size for backbone
drop_path: 0.0            # help='Drop path rate (default: 0.1)    
normlize_target: False     #help='normalized the target patch pixels
 
# Optimizer parameters
opt: "adamw"               # help='Optimizer, default: "adamw"
opt_eps: 1.0e-8             # help='Optimizer Epsilon (default: 1e-8)
opt_betas: null           # type=float, nargs='+  metavar='BETA help='Optimizer Betas (default: None, use opt default)
clip_grad: null           # type=float, None, metavar='NORM help='Clip gradient norm (default: None, no clipping)
momentum: 0.9             # metavar='M help='SGD momentum (default: 0.9)
weight_decay: 0.05        # help='weight decay (default: 0.05)
weight_decay_end: 0.05    # help="""Final value of the
                          # weight decay. We use a cosine schedule for WD. 
                          # (Set the same value with args.weight_decay to keep weight decay no change)""")

lr: 5.0e-4                # metavar='LR help='learning rate (default: 1.5e-4)
warmup_lr: 1.5e-4           # metavar='LR help='warmup learning rate (default: 1e-6)
min_lr: 5.0e-6              # metavar='LR help='lower lr bound for cyclic schedulers that hit 0 (1e-5)

warmup_epochs: 0         # metavar='N help='epochs to warmup LR, if scheduler supports
warmup_steps: -1          # metavar='N help='epochs to warmup LR, if scheduler supports

output_dir: "/mnt/shuang/Output/output_ego4d"                              # help='path where to save, empty for no saving
log_dir: "/mnt/shuang/Output/output_ego4d"                              # help='path where to tensorboard log

resume: ""                                  # help='resume from checkpoint
auto_resume: False                           # 

start_epoch: 0                              # help='start epoch
num_workers: 30
pretrain: "multimodal"

lamb: [0.8, 0.2, 0.2, 0.8]

ckpt: "/mnt/shuang/Output/output_ego4d/ckpt/pretrain_vitb_1600_kinetics400.pth"

# configurations for epic-kitchens dataset
cfg:
  # Data Loading
  ANN_DIR: "/mnt/shuang/Data/ego4d/data/v1/annotations"
  FRAME_DIR_PATH: "/mnt/shuang/Data/ego4d/preprocessed_data/egoclip/"

  NUM_FRAMES: 16 # number of frames sampled from each input clip

  MEAN: [0.485, 0.456, 0.406]
  STD: [0.229, 0.224, 0.225]

  FRAME_FORMAT: "{:010d}.jpg"  # image frame format

  repeat_sample: 1
  short_side_size: 256
  input_size: 224

  task: "egoclip"
  load_flow: "local" # do not load flow, can be one of [local, none]
