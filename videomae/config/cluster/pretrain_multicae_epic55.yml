
batch_size: 6
epochs: 300
save_ckpt_freq: 10

# Model parameters
model: "pretrain_videomae_multicae_base_patch16_224"
decoder_depth: 4
regressor_depth: 4

mask_type: "multimodal"
mask_ratio: 0.95

input_size: 224
drop_path: 0.0
normlize_target: False

# Optimizer parametersd
opt: "adamw"
opt_eps: 1.0e-8
opt_betas: null
clip_grad: null
momentum: 0.9
weight_decay: 0.0001
weight_decay_end: null


lr: 5.0e-5

warmup_lr: 1.0e-7
min_lr: 1.0e-7

warmup_epochs: 20 
warmup_steps: -1


output_dir: "/mnt/shuang/Output/output_ego4d"
log_dir: "/mnt/shuang/Output/output_ego4d"

resume: ""
auto_resume: True

start_epoch: 0
num_workers: 20
pin_mem: true

pretrain: "multicae"
lamb: [1, 1]

# ckpt: "/mnt/shuang/Output/output_ego4d/ckpt/pretrain_vitb_1600_kinetics400.pth"

# configurations for epic-kitchens dataset
cfg:
  task: "epic-kitchens"
  EPICKITCHENS:
    VISUAL_DATA_DIR: "/mnt/shuang/Data/epic-kitchen/3h91syskeag572hl6tvuovwv4d/frames_rgb_flow"
    ANNOTATIONS_DIR: "/mnt/shuang/Data/epic-kitchen/3h91syskeag572hl6tvuovwv4d/annotations"
    TRAIN_LIST: "EPIC_train_action_labels.pkl"
    VAL_LIST: ""
    TEST_LIST: ""

  DATA:
    # do not need in pretrain
    # - MEAN: ""
    # - STD: ""
    SAMPLING_RATE: 2
    NUM_FRAMES: 16
    REPEATED_SAMPLING: 0
    READ_FROM_ZIP: true
    # TRAIN_JITTER_SCALES: [256, 320]
    # TRAIN_CROP_SIZE: 224
    # TEST_CROP_SIZE: 224

  # TEST:
  #   NUM_SPATIAL_CROPS: ""
  #   NUM_ENSEMBLE_VIEWS: ""
  VERSION: 55
  ONINE_EXTRACTING: true
