batch_size: 10
epochs: 100 
update_freq: 1
save_ckpt_freq: 10

# Model parameters
model: 'vit_twohead_multicae_base_patch16_224'
tubelet_size: 2
input_size: 224       # 'videos input size'

drop: 0.0             # metavar='PCT help='Dropout rate (default: 0.)')
attn_drop_rate: 0.0   # metavar='PCT help='Attention dropout rate (default: 0.)')
drop_path: 0.1        # metavar='PCT help='Drop path rate (default: 0.1)')

disable_eval_during_finetuning: false
model_ema: false
model_ema_decay: 0.9999
model_ema_force_cpu: false

# Optimizer parameters
opt: 'adamw'            # metavar='OPTIMIZER help='Optimizer (default: "adamw"')
opt_eps: 1.0e-8         # help='Optimizer Epsilon (default: 1e-8)')
opt_betas: [0.9, 0.999]         # help='Optimizer Betas (default: None, use opt default)')
clip_grad: null         # help='Clip gradient norm (default: None, no clipping)')
momentum: 0.9           # help='SGD momentum (default: 0.9)')
weight_decay: 0.05      # help='weight decay (default: 0.05)')
weight_decay_end: null  # help="""Final value of the
                        # weight decay. We use a cosine schedule for WD and using a larger decay by
                        # the end of training improves performance for ViTs.""")

lr: 5.0e-4              #  help='learning rate (default: 1e-3)')
layer_decay: 0.75
warmup_lr: 1.0e-6       # help='warmup learning rate (default: 1e-6)')
min_lr: 1.0e-6          # help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')

warmup_epochs: 5        # help='epochs to warmup LR, if scheduler supports')
warmup_steps: -1        # help='num of steps to warmup LR, will overload warmup_epochs if set > 0')

# Augmentation parameters
color_jitter: 0.4,                # help='Color jitter factor (default: 0.4)')
num_sample: 1                     # help='Repeated_aug (default: 2)')
aa: 'rand-m7-n4-mstd0.5-inc1'     # help='Use AutoAugment policy. "v0" or "original". " + "(default: rand-m7-n4-mstd0.5-inc1)'),
smoothing: 0.1                    # help='Label smoothing (default: 0.1)')
train_interpolation: 'bicubic'    # help='Training interpolation (random, bilinear, bicubic default: "bicubic")')

# Evaluation parameters
crop_pct: null
short_side_size: 224
test_num_segment: 5
test_num_crop: 3

# Random Erase params
reprob: 0.25                      # help='Random erase prob (default: 0.25)')
remode: 'pixel'                   # help='Random erase mode (default: "pixel")')
recount: 1                        # help='Random erase count (default: 1)')
resplit: false                    # help='Do not random erase first (clean) augmentation split')

# Mixup params
mixup: 0.8                        # help='mixup alpha, mixup enabled if > 0.')
cutmix: 1.0                       # help='cutmix alpha, cutmix enabled if > 0.')
cutmix_minmax: null               # help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')
mixup_prob: 1.0                   # help='Probability of performing mixup or cutmix when either/both is enabled')
mixup_switch_prob: 0.5            # help='Probability of switching to cutmix when both mixup and cutmix enabled')
mixup_mode: 'batch'               # help='How to apply mixup/cutmix params. Per "batch", "pair", or "elem"')

# Finetuning params
finetune: '/data/shared/output/multicae_preepic55_A0/checkpoint-299.pth'
model_key: 'model|module'
model_prefix: ''
init_scale: 0.001
use_mean_pooling: true # if false, then use cls

# Finetuning on ego4d
clip_len: 8 # help="time duration of clip, default is 8s")

# Dataset parameters
data_path: '/path/to/list_kinetics-400'
eval_data_path: null
nb_classes: -1
imagenet_default_mean_and_std: true
num_segments: 1
num_frames: 16
sampling_rate: 4

data_set: 'Ego4d-statechange-classification-localization'

output_dir: /data/shared/output      # help='path where to save, empty for no saving')
log_dir: /data/shared/output        # help='path where to tensorboard log')
# device: 'cuda'      # help='device to use for training / testing')
# seed: 0
resume: ''          # help='resume from checkpoint')
auto_resume: true
flow_mode: ""
save_ckpt: true
start_epoch: 0      # help='start epoch')
# eval: false         # help='Perform evaluation only')
# dist_eval: true    # help='Enabling distributed evaluation')
num_workers: 20
# pin_mem: true

# # distributed training parameters
# world_size: 1             # help='number of distributed processes')
# local_rank: -1
# dist_on_itp: false
# dist_url: 'env://'        # help='url used to set up distributed training')
# enable_deepspeed: true

# name: "temp"              # help="name of current run"

# Added by Jiachen, for ego4d state change pretraining
# debug: true
# anno_path: ""             # help="save path of annotation files of ego4d state change, which includes train.json, val.json, test.json")
# pos_clip_save_path: ""    # help="save path of positive clips of ego4d state change")
# neg_clip_save_path: ""    # help="save path of negative clips of ego4d state change")


lamb_cls: 1
lamb_loc: 1

cfg:
  DATA: 
    # Data Loading
    ANN_DIR: "/data/shared/ego4d/v1/annotations"
    VIDEO_DIR_PATH: "/data/shared/ego4d/v1/full_scale"
    CLIPS_SAVE_PATH: "/data/shared/ego4d/v1/pos"  # "/mnt/shuang/Data/ego4d/preprocessed_data/pos"
    NO_SC_PATH: "/data/shared/ego4d/v1/neg"        # "/mnt/shuang/Data/ego4d/preprocessed_data/neg"

    SAVE_AS_ZIP: True                # save frames in zip file for efficient data loading
    READ_BY_CLIPS: False                  # read by clips or full_scale video

    # Data Sampling
    CLIP_LEN_SEC: 8 # Duration time in second of clip
    CROP_SIZE: 224
    SAMPLING_FPS: 2 # Sampled frames per second for training